{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nHIXkks570Td"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZa7PJFS7wLS"
      },
      "source": [
        "# Libaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m53lH7E82wlZ",
        "outputId": "81eaa175-1aac-45c9-f31d-fbbfcab31fd7"
      },
      "source": [
        "from keras import callbacks\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation,Flatten,Dense,Dropout,Embedding,Bidirectional,LSTM\n",
        "from keras.optimizers import Adam,SGD\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation,Bidirectional,SpatialDropout1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "import gc\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import math\n",
        "\n",
        "import os\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dropout\n",
        "#from kaggle_datasets import KaggleDatasets\n",
        "from tqdm.notebook import tqdm\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHIXkks570Td"
      },
      "source": [
        "# Model declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6gkxy3bSoiS"
      },
      "source": [
        "\"\"\"\n",
        "model declaration and callbacks declaration\n",
        "callbacks are used to exercise control over the model. For instance, callbacks can be used to perform early stopping, model check-pointing,\n",
        "lr reduction over time,\n",
        "\"\"\"\n",
        "def create_model(vocabulary_size,embedding_size,embedding_matrix):\n",
        "    model_glove = Sequential()\n",
        "    model_glove.add(Embedding(vocabulary_size, embedding_size, weights=[embedding_matrix], trainable=False))\n",
        "    model_glove.add(Bidirectional(LSTM(100)))\n",
        "    model_glove.add(Dense(1, activation='sigmoid'))\n",
        "    model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model_glove.summary()\n",
        "    return model_glove\n",
        "\n",
        "\n",
        "def callback(model_name,tf_log_dir_name='./tf-log/',patience_lr=10,):\n",
        "    cb = []\n",
        "    \"\"\"\n",
        "    Tensorboard log callback\n",
        "    \"\"\"\n",
        "    tb = callbacks.TensorBoard(log_dir=tf_log_dir_name, histogram_freq=0)\n",
        "    cb.append(tb)\n",
        "\n",
        "    \"\"\"\n",
        "    Model-Checkpoint\n",
        "    \"\"\"\n",
        "    m = callbacks.ModelCheckpoint(filepath=model_name,monitor='val_loss',mode='auto',save_best_only=True)\n",
        "    cb.append(m)\n",
        "\n",
        "    \"\"\"\n",
        "    Reduce Learning Rate\n",
        "    \"\"\"\n",
        "    reduce_lr_loss = callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=patience_lr, verbose=1, epsilon=1e-4, mode='min')\n",
        "    cb.append(reduce_lr_loss)\n",
        "\n",
        "    \"\"\"\n",
        "    Early Stopping callback\n",
        "    \"\"\"\n",
        "    # Uncomment for usage\n",
        "    early_stop = callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\n",
        "    cb.append(early_stop)\n",
        "\n",
        "\n",
        "\n",
        "    return cb\n",
        "\n",
        "######### Show Train Val History Graph ###############\n",
        "def plot_loss_accu(history,lossLoc='Train_Val_Loss',accLoc='Train_Val_acc'):\n",
        "\n",
        "    plt.clf()\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(len(loss))\n",
        "    plt.plot(epochs, loss, 'r')\n",
        "    plt.plot(epochs, val_loss, 'b')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend(['train', 'val'], loc='upper right')\n",
        "    #plt.show()\n",
        "    plt.savefig(lossLoc)\n",
        "\n",
        "    plt.clf()\n",
        "\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    epochs = range(len(acc))\n",
        "    plt.plot(epochs, acc, 'r')\n",
        "    plt.plot(epochs, val_acc, 'b')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend(['train', 'val'], loc='lower right')\n",
        "    #plt.show()\n",
        "    plt.savefig(accLoc)\n",
        "\n",
        "\n",
        "    return model_glove"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUweaKm-7nYG"
      },
      "source": [
        "# Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvUeQ0aX3s6K",
        "outputId": "eb30cd6f-a068-418d-8abc-0f36423c92a0"
      },
      "source": [
        "!git clone https://github.com/banglakit/bengali-stemmer.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bengali-stemmer'...\n",
            "remote: Enumerating objects: 98, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 98 (delta 6), reused 15 (delta 3), pack-reused 69\u001b[K\n",
            "Unpacking objects: 100% (98/98), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxLl8QaO4Rr1",
        "outputId": "e415b37f-023c-44ab-ade8-0d4a816c49b9"
      },
      "source": [
        "cd \"/content/bengali-stemmer\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/bengali-stemmer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UaaRka136xH"
      },
      "source": [
        "from bengali_stemmer.rafikamal2014 import RafiStemmer\n",
        "stemmer = RafiStemmer()\n",
        "stemmer.stem_word('কেজিতে')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fO-52z_M4aqm",
        "outputId": "74884153-8326-4315-fd2e-b58058c679a6"
      },
      "source": [
        "!pip install bnlp_toolkit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bnlp_toolkit\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/ad/756187f1c389b752abca35946318e4aa7205daa6bedb539441acd66a11f7/bnlp_toolkit-3.1.1-py3-none-any.whl\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Collecting gensim==4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/52/f1417772965652d4ca6f901515debcd9d6c5430969e8c02ee7737e6de61c/gensim-4.0.1-cp37-cp37m-manylinux1_x86_64.whl (23.9MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9MB 121kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (1.4.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 44.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (3.2.5)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (0.8.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.8.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (1.15.0)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 34.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (4.41.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.0.1->bnlp_toolkit) (5.1.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, gensim, sentencepiece, bnlp-toolkit\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed bnlp-toolkit-3.1.1 gensim-4.0.1 python-crfsuite-0.9.7 sentencepiece-0.1.96 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1W1Hl7M2qJL"
      },
      "source": [
        "from bnlp.corpus import stopwords, punctuations\n",
        "stopwordsBNLP = stopwords\n",
        "print(len(stopwordsBNLP))\n",
        "print(punctuations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO0jhaPa3EKp"
      },
      "source": [
        "from bnlp.corpus.util import remove_stopwords\n",
        "from bnlp import NLTKTokenizer\n",
        "\n",
        "def removeForeign(word):\n",
        "  a = \"\".join(i for i in word if 2432 <= ord(i) <= 2559)\n",
        "  return a\n",
        "\n",
        "def makeRemoveHyperLink(text):\n",
        "  result = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
        "  return result\n",
        "\n",
        "def MakeHTMLremove(text):\n",
        "  '''\n",
        "  result = re.compile('(<.*?>)')\n",
        "  result = result.sub(r'', text) \n",
        "  '''\n",
        "  cleancode = re.compile('<code>.*?</code>')\n",
        "  cleanr = re.compile('<.*?>')\n",
        "  cleanentity = re.compile('&.*;')\n",
        "  cleantext = re.sub(cleancode, '', text)\n",
        "  cleantext = re.sub(cleanr, ' ', cleantext)\n",
        "  cleantext = re.sub(cleanentity, ' ', cleantext)\n",
        "  \n",
        "  return cleantext\n",
        "\n",
        "def cleaning(updated):\n",
        "  \n",
        "  #html remove\n",
        "  updated= updated.apply(lambda x: MakeHTMLremove(x))\n",
        "  #hyperlink remove\n",
        "  updated = updated.apply(lambda x: makeRemoveHyperLink(x))\n",
        "  # tokenizer\n",
        "  bnltk = NLTKTokenizer()\n",
        "  updated = updated.apply(lambda x: bnltk.word_tokenize(x))\n",
        "  # remove punctuations\n",
        "  updated = updated.apply(lambda x: [item for item in x if item not in punctuations])\n",
        "  # remove stop words\n",
        "  updated = updated.apply(lambda x: [item for item in x if item not in stopwordsBNLP])\n",
        "  # remove foreign words\n",
        "  updated = updated.apply(lambda x: [ removeForeign(item) for item in x ])\n",
        "  # stripping\n",
        "  updated = updated.apply(lambda x: [item.strip() for item in x ])\n",
        "  # remove numbers\n",
        "  updated = updated.apply(lambda x: [re.sub(r'[০১২৩৪৫৬৭৮৯\\.]+', '', item) for item in x ])\n",
        "  # stemming\n",
        "  updated = updated.apply(lambda x: [stemmer.stem_word(item) for item in x ])\n",
        "  # stripping\n",
        "  updated = updated.apply(lambda x: [item.strip() for item in x ])\n",
        "  \n",
        "  \n",
        "  return updated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAdDZOcs7bFp"
      },
      "source": [
        "# Data Loading and consolidation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6InADQIh7kbj",
        "outputId": "369fc034-388a-4fce-fbad-32b4025c66a7"
      },
      "source": [
        "df1= pd.read_csv('/content/drive/MyDrive/FakeNews/Authentic-48K.csv', engine='python', encoding='utf-8')\n",
        "print(\"df1.shape: \",df1.shape)\n",
        "df2= pd.read_csv('/content/drive/MyDrive/FakeNews/Fake-1K.csv', engine='python', encoding='utf-8')\n",
        "print(\"df2.shape: \",df2.shape)\n",
        "df3= pd.read_csv('/content/drive/MyDrive/FakeNews/LabeledAuthentic-7K.csv', engine='python', encoding='utf-8')\n",
        "print(\"df3.shape: \",df3.shape)\n",
        "df4= pd.read_csv('/content/drive/MyDrive/FakeNews/LabeledFake-1K.csv', engine='python', encoding='utf-8')\n",
        "print(\"df4.shape: \",df4.shape)\n",
        "merged = pd.concat([df1, df2, df3, df4])\n",
        "print(\"merged shape: \",merged.shape)\n",
        "#shuffle\n",
        "merged = merged.sample(frac=1).reset_index(drop=True)\n",
        "print(\"merged columns: \",merged.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df1.shape:  (48678, 7)\n",
            "df2.shape:  (1299, 7)\n",
            "df3.shape:  (7202, 9)\n",
            "df4.shape:  (1299, 10)\n",
            "merged shape:  (58478, 10)\n",
            "merged columns:  Index(['articleID', 'domain', 'date', 'category', 'headline', 'content',\n",
            "       'label', 'source', 'relation', 'F-type'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiDt6RrheGWr",
        "outputId": "9e56fc2a-5a96-48ab-b974-6685e35ae0c5"
      },
      "source": [
        "merged.info(memory_usage=\"deep\")\n",
        "print(\"\\nNon null rows count\\n\")\n",
        "merged.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 58478 entries, 0 to 58477\n",
            "Data columns (total 10 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   articleID  58478 non-null  int64  \n",
            " 1   domain     58478 non-null  object \n",
            " 2   date       58478 non-null  object \n",
            " 3   category   58478 non-null  object \n",
            " 4   headline   58478 non-null  object \n",
            " 5   content    58478 non-null  object \n",
            " 6   label      58478 non-null  float64\n",
            " 7   source     8501 non-null   object \n",
            " 8   relation   8501 non-null   object \n",
            " 9   F-type     1299 non-null   object \n",
            "dtypes: float64(1), int64(1), object(8)\n",
            "memory usage: 233.5 MB\n",
            "\n",
            "Non null rows count\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "articleID        0\n",
              "domain           0\n",
              "date             0\n",
              "category         0\n",
              "headline         0\n",
              "content          0\n",
              "label            0\n",
              "source       49977\n",
              "relation     49977\n",
              "F-type       57179\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "GAp_SVIFednF",
        "outputId": "75544183-c4ef-4f18-98cb-46a810231e0c"
      },
      "source": [
        "merged.drop(['source', 'relation', 'F-type', 'articleID', 'category', 'domain', 'date'], axis=1, inplace=True)\n",
        "merged.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>content</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কিশোরীরা এই উদযাপন তুলে রেখেছিল ট্রফিটার জন্য</td>\n",
              "      <td>আসর জুড়ে একের পর এক ম্যাচ জিতেছে বাংলার কিশোরী...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‘এখন আমি শিল্পী হয়ে গেছি’ ০১ অক্টোবর, ২০১৮ ১৪:২২</td>\n",
              "      <td>সম্পন্ন হল ‘মিস ওয়ার্ল্ড বাংলাদেশ-২০১৮’র আয়োজন...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>উম্মুক্ত পরিবেশেও নির্ঝঞ্ঝাট কাজ নিশ্চিত করবে ...</td>\n",
              "      <td>মো. রায়হান কবির : অনেক অফিসেই খোলামেলা পরিবেশে...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>সংসদ নির্বাচনের বিস্তারিত ইইউকে জানিয়েছি</td>\n",
              "      <td>বর্তমান সরকারই নির্বাচনকালীন সরকারের দায়িত্বে ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>সড়কে চলাচলের সময় সৃষ্টিকর্তাকে স্মরণ করা জরুরি</td>\n",
              "      <td>নিরাপদ সড়ক চাই (নিসচা) এর কেন্দ্রীয় কমিটির চেয়...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>পালুতে অবতরণের অনুমতি পাচ্ছে না বিদেশি ত্রাণবা...</td>\n",
              "      <td>ইন্দোনেশিয়ার ভূমিকম্প ও সুনামিতে বিধ্বস্ত পালু...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>আট দিনের মধ্যে ফিলিস্তিনিদের শহর ছাড়ার নির্দেশ...</td>\n",
              "      <td>আট দিনের মধ্যে পশ্চিম তীরের বেদুইন গ্রামের ফিল...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>সুনামিতে নিহত ৮৪০ জনকে একসঙ্গে বিদায় জানালো ইন...</td>\n",
              "      <td>মরদেহের রঙিন ব্যাগগুলো পাশাপাশি পড়ে আছে মাত্র ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>অর্ধশতাধিক পৌরসভা-ইউপিতে উপনির্বাচনে ভোট কাল</td>\n",
              "      <td>দেশের অর্ধশতাধিক পৌরসভা ও ইউনিয়ন পরিষদের (ইউপি...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>আলোচনায় বসতে মোদিকে ইমরানের চিঠি</td>\n",
              "      <td>পাকিস্তানের প্রধানমন্ত্রী ইমরান খান ভারতের সঙ্...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  ... label\n",
              "0      কিশোরীরা এই উদযাপন তুলে রেখেছিল ট্রফিটার জন্য  ...   1.0\n",
              "1   ‘এখন আমি শিল্পী হয়ে গেছি’ ০১ অক্টোবর, ২০১৮ ১৪:২২  ...   1.0\n",
              "2  উম্মুক্ত পরিবেশেও নির্ঝঞ্ঝাট কাজ নিশ্চিত করবে ...  ...   1.0\n",
              "3           সংসদ নির্বাচনের বিস্তারিত ইইউকে জানিয়েছি  ...   1.0\n",
              "4     সড়কে চলাচলের সময় সৃষ্টিকর্তাকে স্মরণ করা জরুরি  ...   1.0\n",
              "5  পালুতে অবতরণের অনুমতি পাচ্ছে না বিদেশি ত্রাণবা...  ...   1.0\n",
              "6  আট দিনের মধ্যে ফিলিস্তিনিদের শহর ছাড়ার নির্দেশ...  ...   1.0\n",
              "7  সুনামিতে নিহত ৮৪০ জনকে একসঙ্গে বিদায় জানালো ইন...  ...   1.0\n",
              "8       অর্ধশতাধিক পৌরসভা-ইউপিতে উপনির্বাচনে ভোট কাল  ...   1.0\n",
              "9                   আলোচনায় বসতে মোদিকে ইমরানের চিঠি  ...   1.0\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R--EejNfWFL"
      },
      "source": [
        "merged['headline'] = merged['headline'].astype(str)\n",
        "merged['content'] = merged['content'].astype(str)\n",
        "merged.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "o9BRIIxtf_1R",
        "outputId": "014dd31b-c174-45f2-d92e-3422b9257b8e"
      },
      "source": [
        "print(\"Unique Content :\",len(list(set(merged['content']))))\n",
        "print(\"Total rows :\",len(merged))\n",
        "# dropping ALL duplicte values \n",
        "merged.drop_duplicates(subset =\"content\", \n",
        "                     keep = \"first\", inplace = False)\n",
        "merged.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique Content : 52901\n",
            "Total rows : 58478\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>content</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কিশোরীরা এই উদযাপন তুলে রেখেছিল ট্রফিটার জন্য</td>\n",
              "      <td>আসর জুড়ে একের পর এক ম্যাচ জিতেছে বাংলার কিশোরী...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‘এখন আমি শিল্পী হয়ে গেছি’ ০১ অক্টোবর, ২০১৮ ১৪:২২</td>\n",
              "      <td>সম্পন্ন হল ‘মিস ওয়ার্ল্ড বাংলাদেশ-২০১৮’র আয়োজন...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>উম্মুক্ত পরিবেশেও নির্ঝঞ্ঝাট কাজ নিশ্চিত করবে ...</td>\n",
              "      <td>মো. রায়হান কবির : অনেক অফিসেই খোলামেলা পরিবেশে...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>সংসদ নির্বাচনের বিস্তারিত ইইউকে জানিয়েছি</td>\n",
              "      <td>বর্তমান সরকারই নির্বাচনকালীন সরকারের দায়িত্বে ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>সড়কে চলাচলের সময় সৃষ্টিকর্তাকে স্মরণ করা জরুরি</td>\n",
              "      <td>নিরাপদ সড়ক চাই (নিসচা) এর কেন্দ্রীয় কমিটির চেয়...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>পালুতে অবতরণের অনুমতি পাচ্ছে না বিদেশি ত্রাণবা...</td>\n",
              "      <td>ইন্দোনেশিয়ার ভূমিকম্প ও সুনামিতে বিধ্বস্ত পালু...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>আট দিনের মধ্যে ফিলিস্তিনিদের শহর ছাড়ার নির্দেশ...</td>\n",
              "      <td>আট দিনের মধ্যে পশ্চিম তীরের বেদুইন গ্রামের ফিল...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>সুনামিতে নিহত ৮৪০ জনকে একসঙ্গে বিদায় জানালো ইন...</td>\n",
              "      <td>মরদেহের রঙিন ব্যাগগুলো পাশাপাশি পড়ে আছে মাত্র ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>অর্ধশতাধিক পৌরসভা-ইউপিতে উপনির্বাচনে ভোট কাল</td>\n",
              "      <td>দেশের অর্ধশতাধিক পৌরসভা ও ইউনিয়ন পরিষদের (ইউপি...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>আলোচনায় বসতে মোদিকে ইমরানের চিঠি</td>\n",
              "      <td>পাকিস্তানের প্রধানমন্ত্রী ইমরান খান ভারতের সঙ্...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  ... label\n",
              "0      কিশোরীরা এই উদযাপন তুলে রেখেছিল ট্রফিটার জন্য  ...   1.0\n",
              "1   ‘এখন আমি শিল্পী হয়ে গেছি’ ০১ অক্টোবর, ২০১৮ ১৪:২২  ...   1.0\n",
              "2  উম্মুক্ত পরিবেশেও নির্ঝঞ্ঝাট কাজ নিশ্চিত করবে ...  ...   1.0\n",
              "3           সংসদ নির্বাচনের বিস্তারিত ইইউকে জানিয়েছি  ...   1.0\n",
              "4     সড়কে চলাচলের সময় সৃষ্টিকর্তাকে স্মরণ করা জরুরি  ...   1.0\n",
              "5  পালুতে অবতরণের অনুমতি পাচ্ছে না বিদেশি ত্রাণবা...  ...   1.0\n",
              "6  আট দিনের মধ্যে ফিলিস্তিনিদের শহর ছাড়ার নির্দেশ...  ...   1.0\n",
              "7  সুনামিতে নিহত ৮৪০ জনকে একসঙ্গে বিদায় জানালো ইন...  ...   1.0\n",
              "8       অর্ধশতাধিক পৌরসভা-ইউপিতে উপনির্বাচনে ভোট কাল  ...   1.0\n",
              "9                   আলোচনায় বসতে মোদিকে ইমরানের চিঠি  ...   1.0\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4dV5zQpigu6"
      },
      "source": [
        "# Clean and prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdDAut7lilUA",
        "outputId": "390848c9-71c7-401a-b0c3-0489d49556a2"
      },
      "source": [
        "\"\"\"\n",
        "prepend headline to content\n",
        "\"\"\"\n",
        "print(\"headline: \",merged['headline'][200],\" content \",merged['content'][200],)\n",
        "merged['content'] = merged['headline'] +\" \"+ merged['content']\n",
        "print(merged['content'][200])\n",
        "all_words = []\n",
        "for row in merged['content']:\n",
        "  all_words += row.split()\n",
        "vocab_len = len(set(all_words))\n",
        "print(all_words[0:10])\n",
        "print(\"vocab_len: \",vocab_len)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "headline:  মিয়ানমারের ওপর অর্থনৈতিক নিষেধাজ্ঞা আরোপ করতে পারে ইইউ  content  রোহিঙ্গা নির্যাতন ইস্যুতে মিয়ানমারের ওপর অর্থনৈতিক নিষেধাজ্ঞা আরোপের বিষয়ে বিবেচনা করবে ইউরোপীয় ইউনিয়ন। বুধবার এ তথ্য জানিয়েছেন ইইউ'র তিন জ্যেষ্ঠ কর্মকর্তা। তবে এ বিষয়ে এখনো চূড়ান্ত কোন সিদ্ধান্ত নেয়নি ইউরোপের প্রতিনিধিত্বকারী বৃহৎ জোট ইইউ। মিয়ানমারের তৈরী পোষাকসহ বিভিন্ন রপ্তানিমুখী পণ্যের ওপর এ নিষেধাজ্ঞা আরোপ করা হতে পারে বলে ধারণা করা হচ্ছে। এতে করে মিয়ানমারের পণ্য, ইউরোপের বাজারে শুল্কমুক্ত প্রবেশাধিকার হারাবে। এর আগে রোহিঙ্গা মুসলিমদের ওপর নির্বিচারে নির্যাতনের অভিযোগে, মিয়ানমার সেনাবাহিনীর ওপর নিষেধাজ্ঞা আরোপ করে ইউরোপীয় ইউনিয়ন।\n",
            "মিয়ানমারের ওপর অর্থনৈতিক নিষেধাজ্ঞা আরোপ করতে পারে ইইউ রোহিঙ্গা নির্যাতন ইস্যুতে মিয়ানমারের ওপর অর্থনৈতিক নিষেধাজ্ঞা আরোপের বিষয়ে বিবেচনা করবে ইউরোপীয় ইউনিয়ন। বুধবার এ তথ্য জানিয়েছেন ইইউ'র তিন জ্যেষ্ঠ কর্মকর্তা। তবে এ বিষয়ে এখনো চূড়ান্ত কোন সিদ্ধান্ত নেয়নি ইউরোপের প্রতিনিধিত্বকারী বৃহৎ জোট ইইউ। মিয়ানমারের তৈরী পোষাকসহ বিভিন্ন রপ্তানিমুখী পণ্যের ওপর এ নিষেধাজ্ঞা আরোপ করা হতে পারে বলে ধারণা করা হচ্ছে। এতে করে মিয়ানমারের পণ্য, ইউরোপের বাজারে শুল্কমুক্ত প্রবেশাধিকার হারাবে। এর আগে রোহিঙ্গা মুসলিমদের ওপর নির্বিচারে নির্যাতনের অভিযোগে, মিয়ানমার সেনাবাহিনীর ওপর নিষেধাজ্ঞা আরোপ করে ইউরোপীয় ইউনিয়ন।\n",
            "['কিশোরীরা', 'এই', 'উদযাপন', 'তুলে', 'রেখেছিল', 'ট্রফিটার', 'জন্য', 'আসর', 'জুড়ে', 'একের']\n",
            "vocab_len:  424878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "sIXKkPSYHnyi",
        "outputId": "76988f72-aab5-40a9-c675-7e6808685b32"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(merged['content'], merged['label'], test_size=0.2)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "x_train = x_train.reset_index(drop=True)\n",
        "x_test = x_test.reset_index(drop=True)\n",
        "y_train = y_train.reset_index(drop=True)\n",
        "y_test = y_test.reset_index(drop=True)\n",
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(46782,)\n",
            "(11696,)\n",
            "(46782,)\n",
            "(11696,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'‘ঘরে ডেকে এনে জোর করে চুমু খাওয়ার চেষ্টা করেছিল অনুপ’ বলিউড অভিনেতা সালমান খানের উপস্থাপনায় ‘বিগ বস’র দ্বাদশ মৌসুম চলছে। সব সময় আলোচনা-সমালোচনার মধ্যে থাকা এ অনুষ্ঠানকে ঘিরে নতুন করে আলোচনায় এসেছেন বিখ্যাত ভজন গায়ক অনুপ জলোটা। তার বিরুদ্ধে যৌন হেনস্থার অভিযোগ আসছে একের পর এক।\\xa0 এবার এক ইসরাইলি মডেল রিনা গোলানের অভিযোগ নিয়ে নতুন করে বিতর্ক তৈরি হল। রিনা গোলান ২০১১ সালে একটি বই লিখেছিলেন। সেই বইতেই ভজন গায়কের উপরে কাস্টিং কাউচের অভিযোগের কথা উল্লেখ করেছিলেন। তিনি লিখেছিলেন, নিজের ঘরে ডেকে এনে তাকে জোর করে চুমু খাওয়ার\\xa0চেষ্টা করেছিলেন অনুপ জালোটা। এই অভিযোগ অনুপ জালোটা সম্পূর্ণ ভাবে অস্বীকার করলেও সোশ্যাল মিডিয়াতে এখন এই খবর ভাইরাল। অন্যদিকে জসলিন ও অনুপ জালোটার সম্পর্কের জল গড়িয়েছে অনেক দূর।\\xa0 এর আগে, অনীশা সিংহ শর্মা নামের এক মডেল অনুপের বিরুদ্ধে যৌন হেনস্থার অভিযোগ তুলেছেন বলে জানিয়েছে ভারতীয় সংবাদমাধ্যমগুলো। তার অভিযোগ, বর্ষিয়ান এ গায়ক তার সঙ্গে জুটি বেঁধে ‘বিগ বস’-এ প্রতিদ্বন্দ্বিতা করার প্রতিশ্রুতি দিয়ে যৌন মিলনে লিপ্ত হয়েছেন। গত ছ’মাসে তার সঙ্গে অনুপ দু’বার মিলিত হয়েছেন বলেও জানিয়েছেন অনীশা।'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSVY5unsmgSB",
        "outputId": "3078c5ae-4004-4ee8-f042-e07ba75e4476"
      },
      "source": [
        "preprocessed_train=cleaning(x_train.copy())\n",
        "preprocessed_train = preprocessed_train.apply(lambda x: \"\".join(\" \"+item for item in x))\n",
        "print(preprocessed_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0          ঘর ড এন জোর চুমু খাওয় কর অনুপ  বলিউড অভিনেতা...\n",
            "1         যুক্তরাজ্য স্বাধীনত দা উত্তাল স্কটল্যান্ড যুক...\n",
            "2         বগুড়া হিন্দু শিক্ষার্থী গোমাংস খ দেওয় অভিযোগ ...\n",
            "3         অক্টোবর হঠাৎ উত্তাপ একাদশ জাতী সংসদ নির্বাচন ...\n",
            "4         সৌম্যর এশিয়া কাপ মাঝ পথ ডাক পা দুবা গ সুযোগ প...\n",
            "                               ...                        \n",
            "46777     কর্মদিবস  টাক প্রকল্প স্বাক্ষর রাসিক মেয়র কর্...\n",
            "46778      ট্রাফিক সপ্তাহ কাঙ্ক্ষিত সফলতা আসেনি  মাসব্য...\n",
            "46779     খাগড়াছড়ি অনূর্ধ্ব বঙ্গবন্ধু গোল্ডকাপ অনুষ্ঠিত...\n",
            "46780     জামালপুর ডোবা বৃদ্ধ লাশ উদ্ধ জামালপুর সদর উপজ...\n",
            "46781     এশিয়া কাপ আফগান বোর্ড প্রধান পদত্যাগ চল এশিয়া...\n",
            "Name: content, Length: 46782, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36J1SkwCmlyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a05476-5093-4140-dc10-32f7cc1984af"
      },
      "source": [
        "preprocessed_test = cleaning(x_test.copy())\n",
        "preprocessed_test = preprocessed_test.apply(lambda x: \"\".join(\" \"+item for item in x))\n",
        "print(preprocessed_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0         সিরাজদিখান মনোনয়ন প্রত্যাশীর জনসভা অনুষ্ঠিত  ...\n",
            "1         ঢাবির  ক  ইউনিট ভর্তি পরীক্ষা  শতাংশ পাশ ঢাকা...\n",
            "2         জাকির নায়েক  অফিস এনআইএ  হানা কাগজ অনলাইন ডেস...\n",
            "3         সেঞ্চুরির নেশা পে কোহ ভারত হ খেলা মান এক ম্যা...\n",
            "4         আড়াইহাজার শ্বাসরোধ স্ত্রী হত্য অভিযোগ স্টাফ র...\n",
            "                               ...                        \n",
            "11691     টস হের ব্যাটিং বাংলাদেশ ম্যাচ শ্রীলঙ্ক বিপক্ষ...\n",
            "11692      সহানুভূতি দেখা অপমানিত হ আস  জাতী সংসদ ভবন এ...\n",
            "11693      কো সংস্ক কমি সুপারিশ মুক্তিযুদ্ধ চেতনাবিরোধ...\n",
            "11694     জাবির   ইউনিট ভর্তি পরীক্ষা জা প্রতিনিধি জাহা...\n",
            "11695     বিএনপিজামায়াত পুনর্বাসন জন্য ঐক্য ইনু বৃহত্তর...\n",
            "Name: content, Length: 11696, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhFbxvso-ZGi"
      },
      "source": [
        "# Creating Embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvSvmdZw-iGX",
        "outputId": "cb610ba4-c1d3-41fc-f071-cf7e1595b65a"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "tfidf_vectorizer=TfidfVectorizer()\n",
        "train_vector=tfidf_vectorizer.fit_transform(preprocessed_train) #tfidf returns csr matrix which keras can't work with\n",
        "test_vector=tfidf_vectorizer.transform(preprocessed_test)\n",
        "print(\"train vector shape: \",train_vector.shape)\n",
        "print(\"test vector shape: \", test_vector.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train vector shape:  (46782, 18340)\n",
            "test vector shape:  (11696, 18340)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WHp_19pHk_7",
        "outputId": "3f9df5d7-27c4-4315-88ae-8301ba5baa42"
      },
      "source": [
        "# load the whole embedding into memory\n",
        "# embeddings_index = dict()\n",
        "embedding_matrix = []\n",
        "\n",
        "f = open('/content/drive/MyDrive/FakeNews/bn_glove.39M.100d.txt')\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  # word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  # embeddings_index[word] = coefs\n",
        "  embedding_matrix.append(coefs)\n",
        "f.close()\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "print('Loaded %s word vectors.' % len(embedding_matrix))\n",
        "print('shape of embeddings matrix: ',embedding_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 178153 word vectors.\n",
            "shape of embeddings matrix:  (178153, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McFu8azcJaSP"
      },
      "source": [
        "\n",
        "# create a weight matrix for words in training docs\n",
        "# embedding_matrix = zeros((vocab_size, 100))\n",
        "# for word, i in t.word_index.items():\n",
        "# \tembedding_vector = embeddings_index.get(word)\n",
        "# \tif embedding_vector is not None:\n",
        "# \t\tembedding_matrix[i] = embedding_vector\n",
        "# # create a weight matrix for words in training docs\n",
        "# embedding_matrix = zeros((vocab_size, 100))\n",
        "# for word, i in t.word_index.items():\n",
        "# \tembedding_vector = embeddings_index.get(word)\n",
        "# \tif embedding_vector is not None:\n",
        "# \t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6rKWCDz-d0n"
      },
      "source": [
        "# Running the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUuGQVXI727w"
      },
      "source": [
        "\"\"\"\n",
        "Going back to home to create a directory for storing checkpoints\n",
        "\"\"\"\n",
        "!cd .. ;mkdir checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWRojthVS48W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba5e14f8-f34b-4ecb-9b7e-5f76a6839c41"
      },
      "source": [
        "print(type(train_vector))\n",
        "print(type(preprocessed_train))\n",
        "train_vector=train_vector[:,0:512].toarray()\n",
        "test_vector=test_vector[:,0:512].toarray()\n",
        "print(train_vector.shape)\n",
        "print(test_vector.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "(46782, 512)\n",
            "(11696, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI5s8xs62_HM",
        "outputId": "725c1971-6c20-466a-879e-0aa6b8d66692"
      },
      "source": [
        "\"\"\"\n",
        "model run\n",
        "\"\"\"\n",
        "# pickle_load=open('pickle_FullTrain_Guard_Nyt_1_100dim.pickle','rb')\n",
        "# X,y,embedding_matrix=pickle.load(pickle_load)\n",
        "\n",
        "# pickle_load = open('pickle_Valid_Mfull_1_100dim.pickle', 'rb')\n",
        "# X_test, y_test = pickle.load(pickle_load)\n",
        "\n",
        "vocabulary_size = embedding_matrix.shape[0]\n",
        "embedding_size=100\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)##################\n",
        "cvscores_Mfull=[]\n",
        "classfication_report=[]\n",
        "\n",
        "Fold = 1\n",
        "for train, val in kfold.split(train_vector, y_train):\n",
        "    gc.collect()\n",
        "    K.clear_session()\n",
        "    print('Fold: ', Fold)\n",
        "\n",
        "    X_train = train_vector[train]\n",
        "    X_val = train_vector[val]\n",
        "\n",
        "    Y_train = y_train[train]\n",
        "    Y_val = y_train[val]\n",
        "\n",
        "    print(\"Initializing Callback :/...\")\n",
        "    #This is where the best model is saved by the callback (cb)\n",
        "    model_name = '/content/checkpoints/Model_cv_bi_lstm_Fulltrain_1_Callbacks_kfold_'+str(Fold)+'.h5'\n",
        "    cb = callback(model_name=model_name) \n",
        "\n",
        "    # create model\n",
        "    print(\"Creating and Fitting Model...\")\n",
        "    model = create_model(vocabulary_size=vocabulary_size,embedding_size=embedding_size,embedding_matrix=embedding_matrix)\n",
        "\n",
        "    history=model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=10, batch_size=128,shuffle=True,callbacks=cb)##############\n",
        "    ######################### #callback chilo\n",
        "\n",
        "    # Save each fold model\n",
        "    print(\"Saving Model...\")\n",
        "    model_name = '/content/checkpoints/Model_cv_bi_lstm_Fulltrain_1_kfold_' + str(Fold) + '.h5'########################################3\n",
        "    model.save(model_name)#################################################\n",
        "    '''\n",
        "    model = load_model('Models/Bi_LSTM/Cross_Validation/Model_cv_bi_lstm_Fulltrain_1_kfold_' + str(Fold) + '.h5')\n",
        "    model.name='Model_lstm_Fulltrain_1.h5'\n",
        "    '''\n",
        "\n",
        "    # evaluate the model\n",
        "    print(\"Evaluating Model...\")\n",
        "    ##########################################\n",
        "    scores = model.evaluate(test_vector, y_test, verbose=0)\n",
        "    print(\"Eval with Fake or Real %s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
        "    cvscores_Mfull.append(scores[1])\n",
        "\n",
        "    from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
        "\n",
        "    y_pred = model.predict_classes(test_vector)\n",
        "    classfication_report.append(classification_report(y_test, y_pred))\n",
        "    #print('Classification report:\\n', classification_report(y_test, y_pred))\n",
        "    # print('Classification report:\\n',precision_recall_fscore_support(y_test,y_pred))\n",
        "    # print(y_pred)\n",
        "\n",
        "    '''#######################################################\n",
        "    ########### Saving Graph ####################\n",
        "    print(\"Saving graph...\")\n",
        "\n",
        "    plot_loss_accu(history,'Graphs/Train_Val_Loss_Fold_'+str(Fold)+'.png','Graphs/Train_Val_Acc_Fold_'+str(Fold)+'.png')\n",
        "    #######################################################'''\n",
        "\n",
        "    Fold = Fold + 1\n",
        "\n",
        "print(\"Accuracy list of Fake or Real: \",cvscores_Mfull)\n",
        "print(\"%s: %.2f%%\" % (\"Mean Accuracy of Fake or Real: \", np.mean(cvscores_Mfull)))\n",
        "print(\"%s: %.2f%%\" % (\"Standard Deviation of Fake or Real: +/-\", np.std(cvscores_Mfull)))\n",
        "\n",
        "\n",
        "print('Classfication Report:')\n",
        "for cr in classfication_report:\n",
        "    print(cr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold:  1\n",
            "Initializing Callback :/...\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "Creating and Fitting Model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 100)         17815300  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 200)               160800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 17,976,301\n",
            "Trainable params: 161,001\n",
            "Non-trainable params: 17,815,300\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "293/293 [==============================] - 741s 2s/step - loss: 0.1928 - accuracy: 0.9553 - val_loss: 0.1822 - val_accuracy: 0.9554\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 2/10\n",
            "293/293 [==============================] - 714s 2s/step - loss: 0.1799 - accuracy: 0.9565 - val_loss: 0.1823 - val_accuracy: 0.9554\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 3/10\n",
            "293/293 [==============================] - 736s 3s/step - loss: 0.1796 - accuracy: 0.9565 - val_loss: 0.1822 - val_accuracy: 0.9554\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 4/10\n",
            "293/293 [==============================] - 711s 2s/step - loss: 0.1787 - accuracy: 0.9568 - val_loss: 0.1837 - val_accuracy: 0.9554\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 5/10\n",
            "293/293 [==============================] - 713s 2s/step - loss: 0.1763 - accuracy: 0.9576 - val_loss: 0.1822 - val_accuracy: 0.9554\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 6/10\n",
            "293/293 [==============================] - 736s 3s/step - loss: 0.1898 - accuracy: 0.9531 - val_loss: 0.1822 - val_accuracy: 0.9554\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 7/10\n",
            "293/293 [==============================] - 738s 3s/step - loss: 0.1839 - accuracy: 0.9550 - val_loss: 0.1830 - val_accuracy: 0.9554\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 8/10\n",
            "293/293 [==============================] - 738s 3s/step - loss: 0.1839 - accuracy: 0.9551 - val_loss: 0.1823 - val_accuracy: 0.9554\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 9/10\n",
            "293/293 [==============================] - 735s 3s/step - loss: 0.1768 - accuracy: 0.9572 - val_loss: 0.1823 - val_accuracy: 0.9554\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 10/10\n",
            "293/293 [==============================] - 734s 3s/step - loss: 0.1803 - accuracy: 0.9562 - val_loss: 0.1822 - val_accuracy: 0.9554\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Saving Model...\n",
            "Evaluating Model...\n",
            "Eval with Fake or Real accuracy: 0.96%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold:  2\n",
            "Initializing Callback :/...\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "Creating and Fitting Model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 100)         17815300  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 200)               160800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 17,976,301\n",
            "Trainable params: 161,001\n",
            "Non-trainable params: 17,815,300\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "293/293 [==============================] - 723s 2s/step - loss: 0.1959 - accuracy: 0.9374 - val_loss: 0.1792 - val_accuracy: 0.9564\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 2/10\n",
            "293/293 [==============================] - 739s 3s/step - loss: 0.1881 - accuracy: 0.9536 - val_loss: 0.1792 - val_accuracy: 0.9564\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 3/10\n",
            "293/293 [==============================] - 742s 3s/step - loss: 0.1858 - accuracy: 0.9545 - val_loss: 0.1794 - val_accuracy: 0.9564\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 4/10\n",
            "293/293 [==============================] - 734s 3s/step - loss: 0.1808 - accuracy: 0.9561 - val_loss: 0.1796 - val_accuracy: 0.9564\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 5/10\n",
            "293/293 [==============================] - 737s 3s/step - loss: 0.1809 - accuracy: 0.9561 - val_loss: 0.1794 - val_accuracy: 0.9564\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 6/10\n",
            "293/293 [==============================] - 735s 3s/step - loss: 0.1799 - accuracy: 0.9564 - val_loss: 0.1793 - val_accuracy: 0.9564\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 7/10\n",
            "293/293 [==============================] - 735s 3s/step - loss: 0.1826 - accuracy: 0.9554 - val_loss: 0.1795 - val_accuracy: 0.9564\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 8/10\n",
            "293/293 [==============================] - 707s 2s/step - loss: 0.1846 - accuracy: 0.9548 - val_loss: 0.1796 - val_accuracy: 0.9564\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 9/10\n",
            "293/293 [==============================] - 734s 3s/step - loss: 0.1849 - accuracy: 0.9547 - val_loss: 0.1800 - val_accuracy: 0.9564\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 10/10\n",
            "293/293 [==============================] - 736s 3s/step - loss: 0.1788 - accuracy: 0.9566 - val_loss: 0.1795 - val_accuracy: 0.9564\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Saving Model...\n",
            "Evaluating Model...\n",
            "Eval with Fake or Real accuracy: 0.96%\n",
            "Fold:  3\n",
            "Initializing Callback :/...\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "Creating and Fitting Model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 100)         17815300  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 200)               160800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 17,976,301\n",
            "Trainable params: 161,001\n",
            "Non-trainable params: 17,815,300\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "293/293 [==============================] - 722s 2s/step - loss: 0.1966 - accuracy: 0.9548 - val_loss: 0.1786 - val_accuracy: 0.9566\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 2/10\n",
            "293/293 [==============================] - 716s 2s/step - loss: 0.1802 - accuracy: 0.9563 - val_loss: 0.1799 - val_accuracy: 0.9566\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 3/10\n",
            "293/293 [==============================] - 739s 3s/step - loss: 0.1880 - accuracy: 0.9537 - val_loss: 0.1788 - val_accuracy: 0.9566\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 4/10\n",
            "293/293 [==============================] - 712s 2s/step - loss: 0.1781 - accuracy: 0.9570 - val_loss: 0.1787 - val_accuracy: 0.9566\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 5/10\n",
            "293/293 [==============================] - 736s 3s/step - loss: 0.1818 - accuracy: 0.9557 - val_loss: 0.1793 - val_accuracy: 0.9566\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 6/10\n",
            "293/293 [==============================] - 712s 2s/step - loss: 0.1826 - accuracy: 0.9555 - val_loss: 0.1786 - val_accuracy: 0.9566\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 7/10\n",
            "293/293 [==============================] - 738s 3s/step - loss: 0.1829 - accuracy: 0.9553 - val_loss: 0.1788 - val_accuracy: 0.9566\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 8/10\n",
            "293/293 [==============================] - 708s 2s/step - loss: 0.1848 - accuracy: 0.9547 - val_loss: 0.1786 - val_accuracy: 0.9566\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 9/10\n",
            "293/293 [==============================] - 734s 3s/step - loss: 0.1821 - accuracy: 0.9556 - val_loss: 0.1788 - val_accuracy: 0.9566\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 10/10\n",
            "293/293 [==============================] - 710s 2s/step - loss: 0.1882 - accuracy: 0.9536 - val_loss: 0.1786 - val_accuracy: 0.9566\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Saving Model...\n",
            "Evaluating Model...\n",
            "Eval with Fake or Real accuracy: 0.96%\n",
            "Fold:  4\n",
            "Initializing Callback :/...\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "Creating and Fitting Model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 100)         17815300  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 200)               160800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 17,976,301\n",
            "Trainable params: 161,001\n",
            "Non-trainable params: 17,815,300\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            " 10/293 [>.............................] - ETA: 11:05 - loss: 0.3193 - accuracy: 0.9506"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}